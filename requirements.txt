# Budget-Aware AI Squad - Dependencies
# =====================================
# Python 3.14+ required

# LLM Interface (Local Ollama)
ollama>=0.6.0

# AWS SDK (for LocalStack interaction)
boto3>=1.42.0

# Note: Ollama must be installed separately and running locally
# Install: https://ollama.ai
# Run: ollama serve
# Model: ollama pull llama3.1

# Note: LocalStack must be running for cloud simulation
# Install: pip install localstack
# Run: localstack start
